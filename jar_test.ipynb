{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import tqdm\n",
    "import zipfile\n",
    "import io, json, re, zipfile, pickle, html\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, Optional\n",
    "import pandas as pd\n",
    "DATA_PATH = \"/home/azureuser/cloudfiles/code/Users/a.melzer/content\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def as_list(x):\n",
    "    if x is None:\n",
    "        return []\n",
    "    if isinstance(x, list):\n",
    "        return x\n",
    "    # Some lists are stored under \"____listValues\"\n",
    "    if isinstance(x, dict) and \"____listValues\" in x:\n",
    "        return x[\"____listValues\"]\n",
    "    return [x]\n",
    "\n",
    "def get_field_value_list(doc: Dict[str, Any]) -> List[Dict[str, Any]]:\n",
    "    try:\n",
    "        return as_list(doc[\"entityHolderMap\"][\"nl-NL\"][\"dynamicEntity\"][\"fieldValueList\"][\"____listValues\"])\n",
    "    except KeyError:\n",
    "        return []\n",
    "\n",
    "def find_field(field_values: List[Dict[str, Any]], wanted_prefix: str) -> Optional[Any]:\n",
    "    for fv in field_values:\n",
    "        fid = fv.get(\"fieldId\", \"\")\n",
    "        if fid.startswith(wanted_prefix):\n",
    "            val = fv.get(\"value\")\n",
    "            # ClobDynamicValue: nested value under value[\"value\"]\n",
    "            if isinstance(val, dict) and \"value\" in val:\n",
    "                return val[\"value\"]\n",
    "            return val\n",
    "    return None\n",
    "\n",
    "TAG_ID = re.compile(r\"\\[\\[--ContentED\\.([a-z0-9]+)\\|\\|([^|]+)\\|\\|([^|]+)\\|\\|([^-\\]]+)--\\]\\]\", re.IGNORECASE)\n",
    "\n",
    "def extract_content_links(html_text: str) -> List[Dict[str, str]]:\n",
    "    out = []\n",
    "    for m in TAG_ID.finditer(html_text or \"\"):\n",
    "        out.append({\n",
    "            \"content_id\": m.group(1),\n",
    "            \"link_title\": m.group(2),\n",
    "            \"km_id\": m.group(3),\n",
    "            \"type\": m.group(4)\n",
    "        })\n",
    "    return out\n",
    "\n",
    "def strip_html(html_text: Optional[str]) -> str:\n",
    "    if not html_text:\n",
    "        return \"\"\n",
    "    # quick & decent: remove tags; preserve <br> as newline first\n",
    "    t = html_text.replace(\"<br>\", \"\\n\").replace(\"<br/>\", \"\\n\").replace(\"<br />\", \"\\n\")\n",
    "    t = re.sub(r\"<\\/p\\s*>\", \"\\n\", t, flags=re.I)\n",
    "    t = re.sub(r\"<[^>]+>\", \"\", t)\n",
    "    return html.unescape(re.sub(r\"\\n{3,}\", \"\\n\\n\", t)).strip()\n",
    "\n",
    "def get_id(doc: Dict[str, Any]) -> Optional[str]:\n",
    "    try:\n",
    "        return doc[\"entityHolderMap\"][\"nl-NL\"][\"dynamicEntity\"][\"id\"]\n",
    "    except KeyError:\n",
    "        # some files also mirror an \"id\" at top-level of the nl-NL object\n",
    "        return doc.get(\"entityHolderMap\", {}).get(\"nl-NL\", {}).get(\"id\")\n",
    "\n",
    "def get_tags(doc: Dict[str, Any], field_name: str) -> List[str]:\n",
    "    # e.g. \"topic\", \"agentskill\", \"knowledgeBase\"\n",
    "    fields = get_field_value_list(doc)\n",
    "    val = find_field(fields, f\"{field_name}::::\")\n",
    "    # Tag sets come wrapped; walk to selection list\n",
    "    if isinstance(val, dict):\n",
    "        try:\n",
    "            sel = val[\"value\"][\"tagSetSelectionList\"][\"____listValues\"]\n",
    "            return list(sel) if isinstance(sel, list) else []\n",
    "        except Exception:\n",
    "            return []\n",
    "    return []\n",
    "\n",
    "def get_comment_list(doc: Dict[str, Any]) -> List[str]:\n",
    "    try:\n",
    "        return as_list(doc[\"entityHolderMap\"][\"nl-NL\"][\"commentList\"][\"____listValues\"])\n",
    "    except KeyError:\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_json_docs():\n",
    "    jar_paths = glob.glob(DATA_PATH + \"/*cleansed.jar\")\n",
    "    docs = {}\n",
    "    for jar_path in jar_paths:  \n",
    "        with zipfile.ZipFile(jar_path, \"r\") as zf:\n",
    "            members = [m for m in zf.namelist() if m.lower().endswith(\".json\")]\n",
    "            for i, name in tqdm.tqdm(enumerate(members, 1)):\n",
    "                try:\n",
    "                    with zf.open(name, \"r\") as fh:\n",
    "                        raw = fh.read()\n",
    "                    doc = json.loads(raw)\n",
    "                    docs[name] = doc\n",
    "                except Exception as e:\n",
    "                    print(str(e))\n",
    "    return docs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_json(filename,doc):\n",
    "    fvals = get_field_value_list(doc)\n",
    "    title = find_field(fvals, \"title::::\")\n",
    "    public_html = find_field(fvals,\"publicAnswer::::\")\n",
    "    private_html = find_field(fvals, \"privateAnswer::::\")\n",
    "\n",
    "    # some files mirror privateAnswer at nl-NL level too; fallback\n",
    "    if not private_html:\n",
    "        private_html = doc.get(\"entityHolderMap\", {}).get(\"nl-NL\", {}).get(\"privateAnswer\")\n",
    "    if not public_html:\n",
    "        public_html = doc.get(\"entityHolderMap\", {}).get(\"nl-NL\", {}).get(\"publicAnswer\")\n",
    "    rec = {\n",
    "        \"source_file\": filename,\n",
    "        \"id\": get_id(doc),\n",
    "        \"title\": title,\n",
    "        \"private_answer_html\": private_html,\n",
    "        \"private_answer_text\": strip_html(private_html),\n",
    "        \"publicAnswer_html\":  public_html,\n",
    "        \"publicAnswer_text\":  strip_html(public_html),\n",
    "        \"links_in_private_answer\": extract_content_links(private_html or \"\"),\n",
    "        \"topic_tags\": get_tags(doc, \"topic\"),\n",
    "        \"agentskill_tags\": get_tags(doc, \"agentskill\"),\n",
    "        \"knowledgebase_tags\": get_tags(doc, \"knowledgeBase\"),\n",
    "        \"must_read\": bool(find_field(fvals, \"mustRead::::\") == \"true\"),\n",
    "        'full_text' :  \"Public Answer: \" + strip_html(public_html)+ ' Private Answer: ' + strip_html(private_html)\n",
    "    } \n",
    "    return rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3477it [00:01, 2611.44it/s]\n",
      "2672it [00:00, 2911.83it/s]\n"
     ]
    }
   ],
   "source": [
    "extracted = {}\n",
    "json_docs = get_all_json_docs()\n",
    "for key, doc in json_docs.items():\n",
    "    extracted_data = extract_json(key,doc)\n",
    "    extracted[key] = extracted_data\n",
    "extracted_df = pd.DataFrame(extracted.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_duplicates_details(extracted_df):\n",
    "    title_counts = extracted_df.groupby(\"title\").size().reset_index(name=\"count\")\n",
    "    dupes = title_counts[title_counts[\"count\"] > 1]\n",
    "    dupe_details = (\n",
    "        extracted_df[extracted_df[\"title\"].isin(dupes[\"title\"])]\n",
    "        .groupby(\"title\")[[\"id\", \"source_file\"]]\n",
    "        .agg(list)\n",
    "        .reset_index()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_df_nodupes = extracted_df.drop_duplicates(subset='title')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Koppelling met KM nummer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "km_title_map = pd.read_excel(DATA_PATH + '/titel_km_map.xlsx').rename(columns={'Content Title':'title',\"Article Identifier\": 'km_nummer'})\n",
    "km_title_map = km_title_map.drop_duplicates('title').set_index('title')\n",
    "extracted_df_km= extracted_df_nodupes.set_index('title').join(km_title_map).dropna(subset='km_nummer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_df_km.to_pickle(DATA_PATH + \"/extracted_df_km.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lijst met duplicaten exporteren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_df.set_index(\"id\").loc[extracted_df.set_index(\"id\").index.difference(extracted_df_nodupes.set_index(\"id\").index)].to_excel(\"dupelist.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "content",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
